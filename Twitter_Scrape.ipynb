{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "478bb6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import os\n",
    "import snscrape.modules.twitter as sntwt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6da5e34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a functions that deals with user filtering and user addition\n",
    "def users_handler(user_info: sntwt.Tweet, filters: dict):\n",
    "    \"\"\"\n",
    "    this function is used to filter the given Tweet instance by performing the following processes:\n",
    "        1- extracting the user bio/description.\n",
    "        2- check if the bio contains at least one of the keywordws present in filters dict.\n",
    "        3- check if the user follwers count are greater than the limit present in filters dict.\n",
    "    if the user passes these filters his/her information will be added to a data frame.\n",
    "    \n",
    "    :param: user_info -- an instance of snscrape.modules.twitter.Tweet class contains the information about collected tweet.\n",
    "    :param: filters -- a dictionary that contains the filters which the user will be filtered against.\n",
    "    \n",
    "    :return: instance of snscrape.modules.twitter.Tweet class contains the information about the passed tweet.\n",
    "        \n",
    "    \"\"\"\n",
    "    # extracting user info from the collected tweet\n",
    "    user_bio = user_info.user.rawDescription.lower()\n",
    "    user_follower_count = user_info.user.followersCount\n",
    "    \n",
    "    if any(word.lower() in user_bio.split() for word in filters['keywords']):\n",
    "        if not any(undesired_word.lower() in user_bio.split() for undesired_word in filters['unwanted keywords']):\n",
    "            if user_follower_count > filters['followers_count']:\n",
    "                return user_info\n",
    "            else:\n",
    "                return -1\n",
    "        else:\n",
    "            return -1            \n",
    "    else:\n",
    "        return -1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5de44c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def users_adder(main_user_dict, per_itr_user_dict:dict, user_info: sntwt.Tweet):\n",
    "    \"\"\"\n",
    "    this function is used to add the information of the passed user to the df\n",
    "    :param: main_user_dict -- this is the main dictionary that contains the information about the passed users\n",
    "                                {user_name:[list of usernames per user], 'url':[list of urls per user], \n",
    "                                location:[list of locations per user], #followers:[list of #followers per user]} \n",
    "    :param: per_itr_user_dict -- same as main_user_dict but it gets updated every iteration on the key word combination     \n",
    "    :param: user_info -- instance of snscrape.modules.twitter.Tweet class contains the information about the passed tweet.\n",
    "    \n",
    "    :return: tuple of dictionary that contains the passed user info and integer that represent how many user are collected.\n",
    "    \"\"\"\n",
    "    \n",
    "    user_name = user_info.user.username\n",
    "    \n",
    "    user_bio = user_info.user.rawDescription.lower()\n",
    "    \n",
    "    user_url = user_info.url.split('status')[0]\n",
    "    \n",
    "    user_location = user_info.user.location.lower() \n",
    "    \n",
    "    try:\n",
    "        user_website = user_info.user_website\n",
    "    except AttributeError:\n",
    "        user_website = None\n",
    "    \n",
    "    user_follower_count = user_info.user.followersCount\n",
    "    \n",
    "    if not (user_name in main_user_dict['Username']): # cehck to not include duplicate data\n",
    "        \n",
    "        per_itr_user_dict['Username'].append(user_name)\n",
    "        \n",
    "        per_itr_user_dict['Bio'].append(user_bio)\n",
    "        \n",
    "        per_itr_user_dict['profile URL'].append(user_url)\n",
    "        \n",
    "        per_itr_user_dict['Location'].append(user_location)\n",
    "        \n",
    "        per_itr_user_dict['Websites'].append(user_website)\n",
    "            \n",
    "        per_itr_user_dict['#followers'].append(user_follower_count)\n",
    "    \n",
    "   \n",
    "    return per_itr_user_dict, len(per_itr_user_dict['Username'])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aae07f3",
   "metadata": {},
   "source": [
    "### Algorithm description:  \n",
    "\n",
    "the general idea to find the user of interest is: to search Twitter for tweets that contain a set of keywords\n",
    "because the users which we are interested in will likely contribute to these tweets.\n",
    "we will take the following steps:\n",
    "1. create a dictionary that contains:\n",
    "    - words that we want our user's bio to include\n",
    "    - min number of followers of each user\n",
    "    - words that we do not want to include in our search\n",
    "2. generate a combination of 2 words from the previously created keywords\n",
    "3. initialize a main dictionary its key represents the required info to e collected about the users\n",
    "4. looping on the created combination and for each combination:\n",
    "    - create the search query\n",
    "    - initialize a dictionary with the same structure as the main dictionary. its purpose is to store user information\n",
    "    per iteration on the combination.\n",
    "    - for each collected tweet:\n",
    "        - check if the author of this tweet passes the specified criteria by utilizing users_handler() \n",
    "        - if the user pass, add the collected info to `per_iter_user_dict`\n",
    "        - if # the collected users are greater than 10 per combination append the collected info to the main dictionary\n",
    "        - break from the loop\n",
    "5. create a data frame from the generated dictionary and save the file as CSV  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f57eab1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search query is: (CEO OR vice president) -sex -porn -adult -PLAYMATE -Model lang:en until:2023-01-07 since:2020-01-01 \n",
      "\n",
      "\n",
      " collected 2 users\n",
      "\n",
      " collected 4 users\n",
      "\n",
      " collected 6 users\n",
      "\n",
      " collected 8 users\n",
      "\n",
      " collected 10 users\n",
      "breaking the loop\n",
      "search query is: (CEO OR president) -sex -porn -adult -PLAYMATE -Model lang:en until:2023-01-07 since:2020-01-01 \n",
      "\n",
      "\n",
      " collected 2 users\n",
      "\n",
      " collected 4 users\n",
      "\n",
      " collected 6 users\n",
      "\n",
      " collected 8 users\n",
      "\n",
      " collected 10 users\n",
      "breaking the loop\n",
      "search query is: (CEO OR chief) -sex -porn -adult -PLAYMATE -Model lang:en until:2023-01-07 since:2020-01-01 \n",
      "\n",
      "\n",
      " collected 0 users\n",
      "\n",
      " collected 2 users\n",
      "\n",
      " collected 4 users\n",
      "\n",
      " collected 6 users\n"
     ]
    }
   ],
   "source": [
    "# setting the filters up \n",
    "filters = {'keywords':['CEO', 'vice president', 'president',\n",
    "                      'chief', 'founder', 'co funder', 'CTO', 'Congress Women', 'Congress men',\n",
    "                      'senator', 'MP', 'parliament', 'head', 'senior', 'Activist', 'creator', 'board member',\n",
    "                      'Chairman', 'VP', 'Boss'],\n",
    "           'unwanted keywords': ['sex', 'porn', 'adult', 'PLAYMATE', 'Model'],\n",
    "           'followers_count':10000,}\n",
    "\n",
    "# generating combination of the desired words 2 at a time\n",
    "desired_words_combinations = list(itertools.combinations(filters['keywords'], 2))\n",
    "\n",
    "# setting the unwanted words in tweets\n",
    "undsired_words = ' -'.join(filters['unwanted keywords'])\n",
    "\n",
    "main_user_dict = {'Username':[], 'Bio':[], 'profile URL':[], 'Location':[], 'Websites':[],'#followers':[]}\n",
    "\n",
    "for word in desired_words_combinations:\n",
    "    # setting the query\n",
    "    desired_words = ' OR '.join(list(word))\n",
    "    query = '({}) -{} lang:en until:2023-01-07 since:2020-01-01'.format(desired_words, undsired_words)\n",
    "    print(\"search query is: {} \\n\".format(query))\n",
    "    \n",
    "    per_iter_user_dict = {'Username':[], 'Bio':[], 'profile URL':[], 'Location':[], 'Websites':[],'#followers':[]}\n",
    "    \n",
    "    for i, tweet in enumerate(sntwt.TwitterSearchScraper(query).get_items()):\n",
    "\n",
    "        responce = users_handler(tweet, filters)\n",
    "        if responce != -1 :\n",
    "            user_dict, collected_users = users_adder(main_user_dict, per_iter_user_dict, tweet)\n",
    "            if collected_users > 10:   \n",
    "                print('breaking the loop')\n",
    "                main_user_dict['Username'].extend(per_iter_user_dict['Username'])\n",
    "                main_user_dict['Bio'].extend(per_iter_user_dict['Bio'])\n",
    "                main_user_dict['profile URL'].extend(per_iter_user_dict['profile URL'])\n",
    "                main_user_dict['Location'].extend(per_iter_user_dict['Location'])\n",
    "                main_user_dict['Websites'].extend(per_iter_user_dict['Websites'])\n",
    "                main_user_dict['#followers'].extend(per_iter_user_dict['#followers'])\n",
    "                \n",
    "                break\n",
    "            elif i % 100 == 0:\n",
    "                print(i)\n",
    "            \n",
    "            elif collected_users % 2 == 0:\n",
    "                print(\"\\n collected {} users\".format(collected_users))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07ee877",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(main_user_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a481ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Twitter_user_data\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
